{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2373d029",
   "metadata": {},
   "source": [
    "# **Example of using BERT to perform sentiment analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "##Create a sentiment analysis pipeline using a pretrained BERT model.\n",
    "classifier=pipeline(\"sentiment-analysis\"),\n",
    "model=\"bert-base-uncased\"\n",
    "tokenizer=\"bert-base-uncased\"\n",
    "##Test sentences\n",
    "sentences=[\n",
    "    \"I love using BERT for natural language processing tasks!\"\n",
    "    \"I am not a fan of waiting in long lines\"\n",
    "]\n",
    "##Run inference\n",
    "results=classifier(sentences)\n",
    "for sentence, result in zip (sentences, results):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Prediction: {result['label']} | Score: {result['score']:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa8e68",
   "metadata": {},
   "source": [
    "# **OpenAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "261fc7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18b67a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "898ed0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.environ.get('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c662a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt='''\n",
    "You are an AI assistant who can perform the following steps:\n",
    "1. Reason through the problem by describing your thoughts in a \"Thought:\" section.\n",
    "2. When you need to use a tool, output an \"Action:\" section with the tool name and its input.\n",
    "3. After the tool call, you'll see an \"Observation:\" section with the tool's output.\n",
    "4. Continue this cycle of Thought → Action → Observation as needed.\n",
    "5. End with a concise \"Final Answer:\" that answers the user's query.\n",
    "\n",
    "Note:\n",
    "- The chain of thought in \"Thought:\" sections is only visible to you and not part of your final answer.\n",
    "- The user should only see your \"Final Answer:\".\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5f6f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = '''\n",
    "What is the weather in Thunder Bay, Ontario, Canada Today?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efeff80e-dfa1-4107-b7a4-81271d67b6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client=OpenAI()\n",
    "\n",
    "completion=client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09d955d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought:\n",
      "To find out the weather in Thunder Bay, Ontario, Canada today, I can use a weather-related API to get the current weather information for that location.\n",
      "\n",
      "Action:\n",
      "API Call to get the current weather in Thunder Bay, Ontario, Canada.\n",
      "\n",
      "Observation:\n",
      "The current weather information for Thunder Bay, Ontario, Canada is retrieved.\n",
      "\n",
      "Final Answer:\n",
      "I will provide the current weather in Thunder Bay, Ontario, Canada after using the weather API.\n"
     ]
    }
   ],
   "source": [
    "text = completion.choices[0].message.content\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "541c4d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No match found.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = r'Action:\\s*(\\w+)\\(\"([^\"]+)\"\\)'\n",
    "\n",
    "match = re.search(pattern, text)\n",
    "if match:\n",
    "    tool_name = match.group(1)    # 'GetWeather'\n",
    "    tool_input = match.group(2)   # 'Thunder Bay, Ontario, Canada'\n",
    "    print(\"Tool name:\", tool_name)\n",
    "    print(\"Tool input:\", tool_input)\n",
    "else:\n",
    "    print(\"No match found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "551d0b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually set: tool_name = 'GetWeather', tool_input = 'Thunder Bay, Ontario, Canada'\n"
     ]
    }
   ],
   "source": [
    "tool_name = \"GetWeather\"\n",
    "tool_input = \"Thunder Bay, Ontario, Canada\"\n",
    "print(f\"Manually set: tool_name = '{tool_name}', tool_input = '{tool_input}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c70c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def get_current_weather(city_name):\n",
    "    #base_url = \"https://api.openweathermap.org/data/3.0/onecall\"\n",
    "    #params = {\n",
    "    #    \"lat\": 48.3809,\n",
    "    #    \"lon\": 89.2477,\n",
    "    #    \"appid\": os.environ.get('OPENWEATHERMAPS_API_KEY'),\n",
    "    #    \"units\": \"metric\"  # use \"imperial\" for Fahrenheit\n",
    "    #}\n",
    "\n",
    "    # Make the GET request\n",
    "    #response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Raise an exception if there's an HTTP error\n",
    "    #response.raise_for_status()\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    #data = response.json()\n",
    "\n",
    "    # Extract relevant fields from the response\n",
    "    #weather_info = {\n",
    "    #    \"city\": data[\"name\"],\n",
    "    #    \"temperature\": data[\"main\"][\"temp\"],\n",
    "    #    \"description\": data[\"weather\"][0][\"description\"],\n",
    "    #    \"humidity\": data[\"main\"][\"humidity\"]\n",
    "    #}\n",
    "    weather_info = {\n",
    "        \"city\": \"Thunder Bay\",\n",
    "        \"temperature\": -5.2,   # in Celsius\n",
    "        \"description\": \"snow\",\n",
    "        \"humidity\": 85         # in percentage\n",
    "    }   \n",
    "    return weather_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72fafd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city': 'Thunder Bay', 'temperature': -5.2, 'description': 'snow', 'humidity': 85}\n"
     ]
    }
   ],
   "source": [
    "if tool_name == 'GetWeather':\n",
    "    weather_info = get_current_weather(tool_input)\n",
    "    print(weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a3b593e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought:\n",
      "To find out the weather in Thunder Bay, Ontario, Canada today, I can use a weather-related API to get the current weather information for that location.\n",
      "\n",
      "Action:\n",
      "API Call to get the current weather in Thunder Bay, Ontario, Canada.\n",
      "\n",
      "Observation:\n",
      "The current weather information for Thunder Bay, Ontario, Canada is retrieved.\n",
      "\n",
      "Final Answer:\n",
      "I will provide the current weather in Thunder Bay, Ontario, Canada after using the weather API.\n",
      "\n",
      " Observation: {'city': 'Thunder Bay', 'temperature': -5.2, 'description': 'snow', 'humidity': 85}\n"
     ]
    }
   ],
   "source": [
    "updated_text = text + f\"\\n\\n Observation: {weather_info}\"\n",
    "print(updated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76ee5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\",\"content\": user_prompt},\n",
    "        {\"role\": \"assistant\",\"content\": text}, # This is the model's initial simulated response\n",
    "        {\"role\": \"user\",\"content\": updated_text} # This is where the 'Observation' is fed back\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b7de33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer:\n",
      "The current weather in Thunder Bay, Ontario, Canada is as follows: \n",
      "- Temperature: -5.2°C\n",
      "- Description: Snow\n",
      "- Humidity: 85%\n"
     ]
    }
   ],
   "source": [
    "text2 = completion.choices[0].message.content\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12847003",
   "metadata": {},
   "source": [
    "# **Anthropic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "333aca1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q python-dotenv anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0212534b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddc77a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "\n",
    "model_id = \"claude-3-5-sonnet-20241022\"\n",
    "\n",
    "messages=[{\n",
    "  \"role\": \"user\",\n",
    "  \"content\": \"Hello, Claude\",\n",
    "}]\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=model_id,\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    messages=messages\n",
    ")\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be06ed60",
   "metadata": {},
   "source": [
    "# **Cohere**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad6286aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q cohere python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38041df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b609b231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='5c3123d6-174d-4e3b-859e-eaf3f25b3d27' finish_reason='COMPLETE' message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='Hello there! How can I help you today?')], citations=None) usage=Usage(billed_units=UsageBilledUnits(input_tokens=3.0, output_tokens=10.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=204.0, output_tokens=10.0)) logprobs=None\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "co = cohere.ClientV2()\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"hello world!\"}],\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df0427f",
   "metadata": {},
   "source": [
    "# **ai21-Labs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae88974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q ai21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a278717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "from ai21 import AI21Client\n",
    "from ai21.models.chat import ResponseFormat\n",
    "from ai21.models.chat import UserMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e442cd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='chatcmpl-9b014a63-1d6b-57bb-54e4-3ee5796f15cc' choices=[ChatCompletionResponseChoice(index=0, message=AssistantMessage(role='assistant', content=\"The world's smallest mammal is the bumblebee bat, weighing just 2 grams, while the largest is the blue whale, reaching over 150 tons.\", tool_calls=None), logprobs=None, finish_reason='stop')] usage=UsageInfo(prompt_tokens=29, completion_tokens=37, total_tokens=66)\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    UserMessage(\n",
    "        content=\"Tell me something I don't know. Limit the response to 30 words maximum.\"\n",
    "    )\n",
    "]\n",
    "client = AI21Client(api_key=os.environ.get(\"AI21_API_KEY\"))\n",
    "response = client.chat.completions.create(\n",
    "\t\tmodel=\"jamba-large\",\n",
    "\t\tmessages=messages,\n",
    "\t\tn=1,\n",
    "\t\tmax_tokens=2048,\n",
    "\t\ttemperature=0.4,\n",
    "\t\ttop_p=1,\n",
    "\t\tresponse_format=ResponseFormat(type=\"text\"),\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c49ac30",
   "metadata": {},
   "source": [
    "# **Google AI Studio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "171e4c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d57c9107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "911b2469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nutne\\anaconda3\\envs\\project1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, or Artificial Intelligence, isn't a single technology but rather a broad field focused on enabling machines to perform tasks that typically require human intelligence.\n",
      "\n",
      "At its core, **AI works by identifying patterns in data and then using those patterns to make predictions, decisions, or generate new content.**\n",
      "\n",
      "Let's break down the fundamental components and processes:\n",
      "\n",
      "---\n",
      "\n",
      "### The Core Idea: Learning from Data\n",
      "\n",
      "Imagine a child learning to identify a cat. They don't start with a rulebook. Instead, they see many examples: fluffy cats, sleek cats, big cats, small cats, cats in different poses. Their brain gradually builds an internal \"model\" of what a cat looks like by observing common features.\n",
      "\n",
      "AI works similarly. Instead of a brain, we use:\n",
      "\n",
      "1.  **Data (The Fuel):** This is the raw information AI learns from. It can be text, images, audio, numbers, videos, etc. The more data, and the higher its quality, the better the AI can learn.\n",
      "    *   **Labeled Data:** Data that has been pre-categorized or tagged (e.g., thousands of photos labeled \"cat\" or \"not cat\"). This is crucial for **supervised learning**.\n",
      "    *   **Unlabeled Data:** Data without explicit tags, where the AI has to find its own patterns (e.g., a collection of news articles the AI needs to group by topic). Used in **unsupervised learning**.\n",
      "\n",
      "2.  **Algorithms (The Recipes):** These are the sets of instructions, rules, or mathematical models that the AI uses to process the data, find patterns, and make decisions. Think of them as the \"learning methods.\"\n",
      "\n",
      "3.  **Compute Power (The Engine):** Training AI models, especially complex ones, requires immense computational resources, often utilizing specialized hardware like GPUs (Graphics Processing Units) that can perform many calculations simultaneously.\n",
      "\n",
      "---\n",
      "\n",
      "### The Learning Process: Training and Inference\n",
      "\n",
      "1.  **Training (Learning Phase):**\n",
      "    *   **Input:** The AI model is fed vast amounts of data.\n",
      "    *   **Pattern Recognition:** The algorithm analyzes this data, looking for correlations, structures, and recurring features.\n",
      "    *   **Weight Adjustment:** Based on the patterns it finds (and often, based on how \"wrong\" its initial guesses are compared to the labeled data), the algorithm adjusts its internal parameters (often called \"weights\" and \"biases\"). This is like fine-tuning knobs on a machine to get the desired output.\n",
      "    *   **Iteration:** This process is repeated thousands or millions of times, with the AI continually refining its internal model to minimize errors and improve accuracy.\n",
      "    *   **Goal:** To create a \"model\" that has learned to map inputs to desired outputs or identify inherent structures.\n",
      "\n",
      "2.  **Inference (Application Phase):**\n",
      "    *   Once trained, the AI model can be deployed to make predictions or perform tasks on new, unseen data.\n",
      "    *   **New Input:** You give the trained model a new piece of data (e.g., a photo it's never seen).\n",
      "    *   **Prediction:** The model applies the patterns it learned during training to this new data and generates an output (e.g., \"This photo contains a cat with 98% confidence\").\n",
      "\n",
      "---\n",
      "\n",
      "### Key Branches and How They Work\n",
      "\n",
      "Most of what people refer to as \"AI\" today falls under the umbrella of **Machine Learning (ML)** and its powerful subfield, **Deep Learning (DL)**.\n",
      "\n",
      "1.  **Machine Learning (ML):**\n",
      "    *   **Supervised Learning:** The most common type. AI learns from labeled examples (input-output pairs).\n",
      "        *   **How it works:** Predicts an output based on known inputs. If you give it historical house data (size, location, bedrooms) with corresponding prices, it can predict the price of a new house.\n",
      "        *   **Examples:** Spam filters, recommending products, predicting stock prices.\n",
      "    *   **Unsupervised Learning:** AI finds patterns and structures in unlabeled data.\n",
      "        *   **How it works:** Groups similar data points together. If you give it customer purchasing data, it might identify different customer segments without being told beforehand what those segments are.\n",
      "        *   **Examples:** Customer segmentation, anomaly detection, data compression.\n",
      "    *   **Reinforcement Learning (RL):** AI learns by trial and error in an environment, receiving rewards for good actions and penalties for bad ones.\n",
      "        *   **How it works:** An \"agent\" performs actions, observes the outcome, and adjusts its strategy to maximize cumulative reward over time.\n",
      "        *   **Examples:** Training robots, self-driving cars (in simulations), game-playing AI (like AlphaGo).\n",
      "\n",
      "2.  **Deep Learning (DL):**\n",
      "    *   A subset of ML that uses **Artificial Neural Networks (ANNs)** with many layers (hence \"deep\").\n",
      "    *   **How it works:** Inspired by the structure of the human brain, ANNs consist of interconnected \"neurons\" organized in layers. Each neuron takes inputs, performs a calculation, and passes the result to neurons in the next layer. The \"deepness\" allows the network to learn complex, hierarchical features from raw data.\n",
      "        *   **Convolutional Neural Networks (CNNs):** Excellent for image recognition. They learn to detect features like edges, shapes, and textures in images.\n",
      "        *   **Recurrent Neural Networks (RNNs) / Transformers:** Designed for sequential data like text or speech. They have a \"memory\" of previous inputs in a sequence, allowing them to understand context. Transformers are particularly powerful for language tasks.\n",
      "    *   **Examples:** Facial recognition, natural language processing (chatbots, translation), speech recognition, generative AI (creating realistic images or text).\n",
      "\n",
      "---\n",
      "\n",
      "### What AI Doesn't Do (Yet)\n",
      "\n",
      "It's crucial to understand that current AI, especially deep learning, is primarily about **statistical pattern recognition**. It excels at finding correlations in data, but it doesn't:\n",
      "\n",
      "*   **Understand meaning** in the human sense. When a chatbot \"understands\" your query, it's really just predicting the most statistically probable response based on its training.\n",
      "*   **Possess common sense** or generalizable intelligence outside its specific training domain.\n",
      "*   **Have consciousness, emotions, or self-awareness.**\n",
      "*   **Infer causation**, only correlation.\n",
      "\n",
      "---\n",
      "\n",
      "### In Summary:\n",
      "\n",
      "AI works by **ingesting massive amounts of data**, using **algorithms** to **identify intricate patterns** within that data during a **training phase**, and then applying those learned patterns to **make predictions, classifications, or generate new content** on new, unseen data during the **inference phase**. It's a powerful tool for automating complex tasks and extracting insights, constantly evolving as more data, better algorithms, and greater compute power become available.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "response = model.generate_content(\"Explain how AI works\")\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
